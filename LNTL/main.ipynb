{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"main.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPIxtazIdmYpz41Qz77aepT"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Rx5EjcP5wo1H","executionInfo":{"status":"ok","timestamp":1626983502706,"user_tz":-60,"elapsed":26420,"user":{"displayName":"Jack Stelling","photoUrl":"","userId":"10755116166180930038"}},"outputId":"482ab1e8-bf8a-45ee-bb44-2f06a00a8e23"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hMMunGwI1gAD","executionInfo":{"status":"ok","timestamp":1626984765038,"user_tz":-60,"elapsed":166,"user":{"displayName":"Jack Stelling","photoUrl":"","userId":"10755116166180930038"}},"outputId":"dc3d3fc5-bcce-4668-d445-160ed4ddc3ee"},"source":["# If using a remote server it is neccessary to navigate to your workspace\n","import os \n","\n","os.chdir('/content/drive/MyDrive/BiasMitigation/LNTL')\n","print('Directory changed to...',  os.getcwd())"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Directory changed to... /content/drive/MyDrive/BiasMitigation/LNTL\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"c9A8YypuAfBY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626989015887,"user_tz":-60,"elapsed":3192,"user":{"displayName":"Jack Stelling","photoUrl":"","userId":"10755116166180930038"}},"outputId":"6e29bb1f-7e2b-45be-81ff-0cd12b2b0691"},"source":["# -*- coding: utf-8 -*-\n","\n","# file imports\n","! pip install import-ipynb \n","import import_ipynb\n","import random\n","from option import get_option\n","from trainer import *\n","from utils.utils_LNTL import save_option\n","from data_loaders.data_loader import *\n","\n","# torch imports\n","import torch\n","from torch.backends import cudnn\n","import torchvision.datasets as datasets\n","import torchvision.transforms as transforms\n","import torch.utils.data as data\n","\n","# argparse jupyter workaround\n","from argparse import Namespace\n","# manually add the options becuase using juypter not command line:\n","# Must make it a Namespace class to be used as the argparser would be\n","root = '/content/drive/MyDrive/BiasMitigation/'\n","\n","args = Namespace(exp_name = 'deeplab_greyscale',\n","                 n_class = 10,\n","                 input_size = 28,\n","                 batch_size = 8,\n","                 momentum = 0.9,\n","                 lr = 0.001,\n","                 lr_decay_rate = 0.1,\n","                 lr_decay_period = 40,\n","                 weight_decay = 0.0005,\n","                 max_step = 100,\n","                 depth = 20,\n","                 color_var = 0.020,  \n","                 seed = 2,\n","                 ##############\n","                 #checkpoint = 'path/to/pretrained/model.pth', \n","                 log_step = 50 ,\n","                 save_step = 10,\n","                 data_dir = root + 'Datasets/Cityscapes/',\n","                 metadata_dir = root + 'Datasets/Cityscapes/meta'\n","                 save_dir = root + 'LNTL/training_logs',\n","                 data_split = 'train',\n","                 use_pretrain = True, \n","                 train_baseline = True,\n","                 train_greyscale = True,\n","                 #############\n","                 random_seed = None,\n","                 num_workers = 4,\n","                 cudnn_benchmark = True,\n","                 #############\n","                 cuda = True ,\n","                 debug = False, \n","                 is_train = True,  \n","                 #############\n","                 network_type = 'Deeplab'\n","                 )\n","\n","\n","'''\n","parser.add_argument('-e', '--exp_name',   required=True,              help='experiment name')\n","\n","parser.add_argument('--n_class',          default=10,     type=int,   help='number of classes')\n","parser.add_argument('--input_size',       default=28,     type=int,   help='input size')\n","parser.add_argument('--batch_size',       default=128,    type=int,   help='mini-batch size')\n","parser.add_argument('--momentum',         default=0.9,    type=float, help='sgd momentum')\n","parser.add_argument('--lr',               default=0.01,   type=float, help='initial learning rate')\n","parser.add_argument('--lr_decay_rate',    default=0.1,    type=float, help='lr decay rate')\n","parser.add_argument('--lr_decay_period',  default=40,     type=int,   help='lr decay period')\n","parser.add_argument('--weight_decay',     default=0.0005, type=float, help='sgd optimizer weight decay')\n","parser.add_argument('--max_step',         default=100,    type=int,   help='maximum step for training')\n","parser.add_argument('--depth',            default=20,     type=int,   help='depth of network')\n","parser.add_argument('--color_var',        default=0.03,   type=float, help='variance for color distribution')\n","parser.add_argument('--seed',             default=2,      type=int,   help='seed index')\n","\n","\n","parser.add_argument('--checkpoint',       default=None,               help='checkpoint to resume')\n","parser.add_argument('--log_step',         default=50,     type=int,   help='step for logging in iteration')\n","parser.add_argument('--save_step',        default=10,     type=int,   help='step for saving in epoch')\n","parser.add_argument('--data_dir',         default='./',               help='data directory')\n","parser.add_argument('--save_dir',         default='./',               help='save directory for checkpoint')\n","parser.add_argument('--data_split',       default='train',            help='data split to use')\n","parser.add_argument('--use_pretrain',     action='store_true',        help='whether it use pre-trained parameters if exists')\n","parser.add_argument('--train_baseline',   action='store_true',        help='whether it train baseline or unlearning')\n","parser.add_argument('--train_greyscale',  action='store_true',        help='whether to convert the images to greyscale to get a measure of no colour information')\n","\n","parser.add_argument('--random_seed',                      type=int,   help='random seed')\n","parser.add_argument('--num_workers',      default=4,      type=int,   help='number of workers in data loader')\n","parser.add_argument('--cudnn_benchmark',  default=True,   type=bool,  help='cuDNN benchmark')\n","\n","\n","parser.add_argument('--cuda',             action='store_true',        help='enables cuda')\n","parser.add_argument('-d', '--debug',      action='store_true',        help='debug mode')\n","parser.add_argument('--is_train',         action='store_true',        help='whether it is training')\n","'''\n","\n","\n","def backend_setting(option):\n","    log_dir = os.path.join(option.save_dir, option.exp_name)\n","    if not os.path.exists(log_dir):\n","        os.makedirs(log_dir)\n","\n","    if option.random_seed is None:\n","        option.random_seed = random.randint(1,10000)\n","    torch.manual_seed(option.random_seed)\n","\n","    if torch.cuda.is_available() and not option.cuda:\n","        print('WARNING: GPU is available, but we are not using it')\n","\n","    if not torch.cuda.is_available() and option.cuda:\n","        option.cuda = False\n","        print('Warning: Youve asked for CUDA but no GPU is available...setting CUDA to False')\n","\n","    if option.cuda:\n","        os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'\n","        #os.environ['CUDA_VISIBLE_DEVICES'] = ','.join([str(i) for i in option.gpu_ids])\n","        torch.cuda.manual_seed_all(option.random_seed)\n","        cudnn.benchmark = option.cudnn_benchmark\n","    \n","    if option.train_baseline:\n","        option.is_train = True\n","\n","\n","def main():\n","    #option = get_option()\n","    option = args\n","    # debug:\n","    # print(option)\n","    \n","    backend_setting(option)\n","    # trainer = Trainer(option)\n","\n","    # custom_loader = data_loader.WholeDataLoader(option)\n","    # trainval_loader = torch.utils.data.DataLoader(custom_loader,\n","    #                                               batch_size=option.batch_size,\n","    #                                               shuffle=True,\n","    #                                               num_workers=option.num_workers)\n","\n","\n","    if option.is_train:\n","        print('args works')    \n","    #   save_option(option)\n","    #   trainer.train(trainval_loader)\n","    else:\n","        print('still works')\n","    #   trainer._validate(trainval_loader)\n","\n","    #     pass\n","\n","if __name__ == '__main__': main()"],"execution_count":32,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: import-ipynb in /usr/local/lib/python3.7/dist-packages (0.1.3)\n","Namespace(batch_size=8, color_var=0.02, cuda=True, cudnn_benchmark=True, data_dir='/content/drive/MyDrive/BiasMitigation/Datasets/Cityscapes/', data_split='train', debug=False, depth=20, exp_name='unlearn_0.02', input_size=28, is_train=True, log_step=50, lr=0.001, lr_decay_period=40, lr_decay_rate=0.1, max_step=100, momentum=0.9, n_class=10, network_type='Deeplab', num_workers=4, random_seed=None, save_dir='/content/drive/MyDrive/BiasMitigation/LNTL/training_logs', save_step=10, seed=2, train_baseline=True, train_greyscale=True, use_pretrain=True, weight_decay=0.0005)\n","Warning: Youve asked for CUDA but no GPU is available...setting CUDA to False\n","args works\n"],"name":"stdout"}]}]}