{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"main.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOn08+g672FckkpRctVgbZG"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Rx5EjcP5wo1H","executionInfo":{"status":"ok","timestamp":1627048936043,"user_tz":-60,"elapsed":23907,"user":{"displayName":"Jack Stelling","photoUrl":"","userId":"10755116166180930038"}},"outputId":"c11e746a-fa61-4fc2-93b4-a384d423e65c"},"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hMMunGwI1gAD","executionInfo":{"status":"ok","timestamp":1627048940765,"user_tz":-60,"elapsed":220,"user":{"displayName":"Jack Stelling","photoUrl":"","userId":"10755116166180930038"}},"outputId":"e10545d8-29d1-4f11-bb25-f66e172c3bd8"},"source":["# If using a remote server it is neccessary to navigate to your workspace\n","import os \n","\n","os.chdir('/content/drive/MyDrive/BiasMitigation/LNTL')\n","print('Directory changed to...',  os.getcwd())"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Directory changed to... /content/drive/MyDrive/BiasMitigation/LNTL\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"c9A8YypuAfBY","colab":{"base_uri":"https://localhost:8080/","height":690},"executionInfo":{"status":"error","timestamp":1627048971365,"user_tz":-60,"elapsed":27089,"user":{"displayName":"Jack Stelling","photoUrl":"","userId":"10755116166180930038"}},"outputId":"18faede6-a91b-4f6c-9555-08f176697335"},"source":["# -*- coding: utf-8 -*-\n","\n","# file imports\n","! pip install import-ipynb \n","import import_ipynb\n","import random\n","from option import get_option\n","from trainer_merger import *\n","from utils.utils_LNTL import save_option\n","from data_loaders.data_loader_cityscapes import *\n","\n","# torch imports\n","import torch\n","from torch.backends import cudnn\n","import torchvision.datasets as datasets\n","import torchvision.transforms as transforms\n","import torch.utils.data as data\n","\n","# argparse jupyter workaround\n","from argparse import Namespace\n","# manually add the options becuase using juypter not command line:\n","# Must make it a Namespace class to be used as the argparser would be\n","root = '/content/drive/MyDrive/BiasMitigation/'\n","\n","args = Namespace(exp_name = 'deeplab_greyscale',\n","                 n_class = 10,\n","                 input_size = 28,\n","                 batch_size = 8,\n","                 momentum = 0.9,\n","                 lr = 0.001,\n","                 lr_decay_rate = 0.1,\n","                 lr_decay_period = 40,\n","                 weight_decay = 0.0005,\n","                 max_step = 100,\n","                 depth = 20,\n","                 color_var = 0.020,  \n","                 seed = 2,\n","                 ##############\n","                 #checkpoint = 'path/to/pretrained/model.pth', \n","                 log_step = 50 ,\n","                 save_step = 10,\n","                 data_dir = root + 'Datasets/Cityscapes/',\n","                 meta_dir = root + 'Datasets/Cityscapes/meta',\n","                 save_dir = root + 'LNTL/training_logs',\n","                 data_split = 'train',\n","                 use_pretrain = True, \n","                 train_baseline = True,\n","                 train_greyscale = True,\n","                 #############\n","                 random_seed = None,\n","                 num_workers = 4,\n","                 cudnn_benchmark = True,\n","                 #############\n","                 cuda = True ,\n","                 debug = False, \n","                 is_train = True,  \n","                 #############\n","                 network_type = 'Deeplab'\n","                 )\n","\n","\n","'''\n","parser.add_argument('-e', '--exp_name',   required=True,              help='experiment name')\n","\n","parser.add_argument('--n_class',          default=10,     type=int,   help='number of classes')\n","parser.add_argument('--input_size',       default=28,     type=int,   help='input size')\n","parser.add_argument('--batch_size',       default=128,    type=int,   help='mini-batch size')\n","parser.add_argument('--momentum',         default=0.9,    type=float, help='sgd momentum')\n","parser.add_argument('--lr',               default=0.01,   type=float, help='initial learning rate')\n","parser.add_argument('--lr_decay_rate',    default=0.1,    type=float, help='lr decay rate')\n","parser.add_argument('--lr_decay_period',  default=40,     type=int,   help='lr decay period')\n","parser.add_argument('--weight_decay',     default=0.0005, type=float, help='sgd optimizer weight decay')\n","parser.add_argument('--max_step',         default=100,    type=int,   help='maximum step for training')\n","parser.add_argument('--depth',            default=20,     type=int,   help='depth of network')\n","parser.add_argument('--color_var',        default=0.03,   type=float, help='variance for color distribution')\n","parser.add_argument('--seed',             default=2,      type=int,   help='seed index')\n","\n","\n","parser.add_argument('--checkpoint',       default=None,               help='checkpoint to resume')\n","parser.add_argument('--log_step',         default=50,     type=int,   help='step for logging in iteration')\n","parser.add_argument('--save_step',        default=10,     type=int,   help='step for saving in epoch')\n","parser.add_argument('--data_dir',         default='./',               help='data directory')\n","parser.add_argument('--save_dir',         default='./',               help='save directory for checkpoint')\n","parser.add_argument('--data_split',       default='train',            help='data split to use')\n","parser.add_argument('--use_pretrain',     action='store_true',        help='whether it use pre-trained parameters if exists')\n","parser.add_argument('--train_baseline',   action='store_true',        help='whether it train baseline or unlearning')\n","parser.add_argument('--train_greyscale',  action='store_true',        help='whether to convert the images to greyscale to get a measure of no colour information')\n","\n","parser.add_argument('--random_seed',                      type=int,   help='random seed')\n","parser.add_argument('--num_workers',      default=4,      type=int,   help='number of workers in data loader')\n","parser.add_argument('--cudnn_benchmark',  default=True,   type=bool,  help='cuDNN benchmark')\n","\n","\n","parser.add_argument('--cuda',             action='store_true',        help='enables cuda')\n","parser.add_argument('-d', '--debug',      action='store_true',        help='debug mode')\n","parser.add_argument('--is_train',         action='store_true',        help='whether it is training')\n","'''\n","\n","\n","def backend_setting(option):\n","    log_dir = os.path.join(option.save_dir, option.exp_name)\n","    if not os.path.exists(log_dir):\n","        os.makedirs(log_dir)\n","\n","    if option.random_seed is None:\n","        option.random_seed = random.randint(1,10000)\n","    torch.manual_seed(option.random_seed)\n","\n","    if torch.cuda.is_available() and not option.cuda:\n","        print('WARNING: GPU is available, but we are not using it')\n","\n","    if not torch.cuda.is_available() and option.cuda:\n","        option.cuda = False\n","        print('Warning: Youve asked for CUDA but no GPU is available...setting CUDA to False')\n","\n","    if option.cuda:\n","        os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'\n","        #os.environ['CUDA_VISIBLE_DEVICES'] = ','.join([str(i) for i in option.gpu_ids])\n","        torch.cuda.manual_seed_all(option.random_seed)\n","        cudnn.benchmark = option.cudnn_benchmark\n","    \n","    if option.train_baseline:\n","        option.is_train = True\n","\n","\n","def main():\n","    #option = get_option()\n","    option = args\n","    #debug:\n","    #print(option)\n","    \n","    backend_setting(option)\n","    trainer = Trainer(option)\n","\n","    #custom_loader = data_loader_cityscapes.WholeDataLoader(option)\n","    train_dataset = data_loader_cityscapes.DatasetTrain(option)\n","    val_dataset = data_loader_cityscapes.DatasetVal(option)\n","\n","    trainval_loader = torch.utils.data.DataLoader(custom_loader,\n","                                                  batch_size=option.batch_size,\n","                                                  shuffle=True,\n","                                                  num_workers=option.num_workers)\n","\n","    if option.is_train:\n","    #    print('args works')    \n","        save_option(option)\n","        trainer.train(trainval_loader)\n","    else:\n","    #    print('still works')\n","        trainer._validate(trainval_loader)\n","\n","        pass\n","\n","if __name__ == '__main__': main()"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Collecting import-ipynb\n","  Downloading import-ipynb-0.1.3.tar.gz (4.0 kB)\n","Building wheels for collected packages: import-ipynb\n","  Building wheel for import-ipynb (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for import-ipynb: filename=import_ipynb-0.1.3-py3-none-any.whl size=2975 sha256=3d6b6ada6ef8fc925d5ed709def06c7bd13540bb9593a5a9f1a146b058953d7f\n","  Stored in directory: /root/.cache/pip/wheels/b1/5e/dc/79780689896a056199b0b9f24471e3ee184fbd816df355d5f0\n","Successfully built import-ipynb\n","Installing collected packages: import-ipynb\n","Successfully installed import-ipynb-0.1.3\n","importing Jupyter notebook from option.ipynb\n","importing Jupyter notebook from trainer_merger.ipynb\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Changed the local path to.... /content/drive/MyDrive/BiasMitigation/LNTL\n","Requirement already satisfied: import_ipynb in /usr/local/lib/python3.7/dist-packages (0.1.3)\n","importing Jupyter notebook from /content/drive/My Drive/BiasMitigation/LNTL/models/Deeplab/deeplabv3.ipynb\n","importing Jupyter notebook from /content/drive/My Drive/BiasMitigation/LNTL/models/Deeplab/resnet.ipynb\n","importing Jupyter notebook from /content/drive/My Drive/BiasMitigation/LNTL/models/Deeplab/aspp.ipynb\n","importing Jupyter notebook from /content/drive/My Drive/BiasMitigation/LNTL/models/SegNet/segnet.ipynb\n","importing Jupyter notebook from /content/drive/My Drive/BiasMitigation/LNTL/models/biashead.ipynb\n","importing Jupyter notebook from /content/drive/My Drive/BiasMitigation/LNTL/utils/utils_LNTL.ipynb\n","importing Jupyter notebook from /content/drive/My Drive/BiasMitigation/LNTL/data_loaders/data_loader.ipynb\n","pretrained resnet, 18\n"],"name":"stdout"},{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-80fa1fe41b31>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-3-80fa1fe41b31>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moption\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m     \u001b[0mcustom_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWholeDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moption\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m     trainval_loader = torch.utils.data.DataLoader(custom_loader,\n\u001b[1;32m    137\u001b[0m                                                   \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moption\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'data_loader' is not defined"]}]}]}