{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"main.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNaAsVz7pFP3B7BIWK2v6tD"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Rx5EjcP5wo1H","executionInfo":{"status":"ok","timestamp":1627488278773,"user_tz":-60,"elapsed":1490,"user":{"displayName":"Jack Stelling","photoUrl":"","userId":"10755116166180930038"}},"outputId":"6f02bc73-af6f-4124-a256-e7e443666228"},"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hMMunGwI1gAD","executionInfo":{"status":"ok","timestamp":1627488278773,"user_tz":-60,"elapsed":5,"user":{"displayName":"Jack Stelling","photoUrl":"","userId":"10755116166180930038"}},"outputId":"90588520-28aa-4599-8c2a-ae0a9be56a47"},"source":["# If using a remote server it is neccessary to navigate to your workspace\n","import os \n","\n","os.chdir('/content/drive/MyDrive/BiasMitigation/LNTL')\n","print('Directory changed to...',  os.getcwd())"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Directory changed to... /content/drive/MyDrive/BiasMitigation/LNTL\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"c9A8YypuAfBY","colab":{"base_uri":"https://localhost:8080/","output_embedded_package_id":"16kyYAz0Uc7HAjKjY9smjpiSDMd3RWzyH"},"executionInfo":{"status":"ok","timestamp":1627526520136,"user_tz":-60,"elapsed":36330645,"user":{"displayName":"Jack Stelling","photoUrl":"","userId":"10755116166180930038"}},"outputId":"6313782e-d6bb-46d5-ffba-37f48f1480ed"},"source":["# -*- coding: utf-8 -*-\n","\n","# file imports\n","! pip install import-ipynb \n","import import_ipynb\n","import random\n","from option import get_option\n","from trainer_merger import *\n","from utils.utils_LNTL import save_option\n","from data_loaders.data_loader_cityscapes import *\n","\n","# torch imports\n","import torch\n","from torch.backends import cudnn\n","import torchvision.datasets as datasets\n","import torchvision.transforms as transforms\n","import torch.utils.data as data\n","\n","# argparse jupyter workaround\n","from argparse import Namespace\n","# manually add the options becuase using juypter not command line:\n","# Must make it a Namespace class to be used as the argparser would be\n","root = '/content/drive/MyDrive/BiasMitigation/'\n","\n","args = Namespace(exp_name = 'Exp1_Stage1', # Enter in format Exp1_Stage2\n","                 #n_class = 10,\n","                 #input_size = 28,\n","                 batch_size = 4,\n","                 momentum = 0.9,\n","                 optimiser = 'ADAM',  # accepts either ADAM or SGD\n","                 lr = 0.0001,  # try lr = 0.0001 for ADAM and lr = 0.001 SGD \n","                 lr_decay_rate = 0.1,\n","                 lr_decay_period = 40,\n","                 weight_decay = 0.0001, #arbitrary value off net doubt we have time to tune. would like some paper to back up this ebing a good value\n","                 max_step = 100,\n","                 #depth = 20,\n","                 #color_var = 0.020,  \n","                 seed = 2,\n","                 ##############\n","                 checkpoint = None, \n","                 log_step = 100 ,\n","                 save_step = 1, # save every epoch\n","                 dataset = 'Cityscapes',\n","                 data_dir = root + 'Datasets/Cityscapes/',\n","                 meta_dir = root + 'Datasets/Cityscapes/meta',\n","                 save_dir = root + 'LNTL/training_logs',\n","                 data_split = 'train',\n","                 use_pretrain = False, \n","                 train_baseline = False,\n","                 train_greyscale = False,\n","                 #############\n","                 random_seed = None,\n","                 num_workers = 2,\n","                 cudnn_benchmark = True,\n","                 #############\n","                 cuda = True ,\n","                 debug = False, \n","                 is_train = True,  \n","                 #############\n","                 network_type = 'Deeplab',  # Enter only Deeplab or SegNet\n","                 notes = 'First run of learning not to learn, using cityscapes and deeplab, we could use a pretrained checkpoint to load weigths in in future'\n","                 )\n","\n","\n","'''\n","parser.add_argument('-e', '--exp_name',   required=True,              help='experiment name')\n","\n","parser.add_argument('--n_class',          default=10,     type=int,   help='number of classes')\n","parser.add_argument('--input_size',       default=28,     type=int,   help='input size')\n","parser.add_argument('--batch_size',       default=128,    type=int,   help='mini-batch size')\n","parser.add_argument('--momentum',         default=0.9,    type=float, help='sgd momentum')\n","parser.add_argument('--lr',               default=0.01,   type=float, help='initial learning rate')\n","parser.add_argument('--lr_decay_rate',    default=0.1,    type=float, help='lr decay rate')\n","parser.add_argument('--lr_decay_period',  default=40,     type=int,   help='lr decay period')\n","parser.add_argument('--weight_decay',     default=0.0005, type=float, help='sgd optimizer weight decay')\n","parser.add_argument('--max_step',         default=100,    type=int,   help='maximum step for training')\n","parser.add_argument('--depth',            default=20,     type=int,   help='depth of network')\n","parser.add_argument('--color_var',        default=0.03,   type=float, help='variance for color distribution')\n","parser.add_argument('--seed',             default=2,      type=int,   help='seed index')\n","\n","\n","parser.add_argument('--checkpoint',       default=None,               help='checkpoint to resume')\n","parser.add_argument('--log_step',         default=50,     type=int,   help='step for logging in iteration')\n","parser.add_argument('--save_step',        default=10,     type=int,   help='step for saving in epoch')\n","parser.add_argument('--data_dir',         default='./',               help='data directory')\n","parser.add_argument('--save_dir',         default='./',               help='save directory for checkpoint')\n","parser.add_argument('--data_split',       default='train',            help='data split to use')\n","parser.add_argument('--use_pretrain',     action='store_true',        help='whether it use pre-trained parameters if exists')\n","parser.add_argument('--train_baseline',   action='store_true',        help='whether it train baseline or unlearning')\n","parser.add_argument('--train_greyscale',  action='store_true',        help='whether to convert the images to greyscale to get a measure of no colour information')\n","\n","parser.add_argument('--random_seed',                      type=int,   help='random seed')\n","parser.add_argument('--num_workers',      default=4,      type=int,   help='number of workers in data loader')\n","parser.add_argument('--cudnn_benchmark',  default=True,   type=bool,  help='cuDNN benchmark')\n","\n","\n","parser.add_argument('--cuda',             action='store_true',        help='enables cuda')\n","parser.add_argument('-d', '--debug',      action='store_true',        help='debug mode')\n","parser.add_argument('--is_train',         action='store_true',        help='whether it is training')\n","'''\n","\n","def log_file_setup(option):\n","    # setting up training log files:\n","    if option.train_baseline:\n","        if option.train_greyscale:\n","            kind = 'baseline_greyscale'\n","            path = option.save_dir + '/' + option.network_type + '/' + option.dataset + '/baseline' + '/greyscale' + '/' + option.exp_name \n","            if not os.path.exists(path):\n","                os.makedirs(path)\n","        else:\n","            kind = 'baseline_colour'\n","            # path = os.path.join(option.save_dir, '/' , option.network_type, '/', option.dataset, '/baseline', '/colour', '/', option.exp_name )\n","            path = option.save_dir + '/' + option.network_type + '/' + option.dataset + '/baseline' + '/colour' + '/' + option.exp_name\n","            if not os.path.exists(path):\n","                os.makedirs(path)\n","    else:\n","        kind = 'LNTL'\n","        #path = os.path.join(option.save_dir, '/' , option.network_type, '/', option.dataset, '/LNTL', '/', option.exp_name )\n","        path = option.save_dir + '/' + option.network_type + '/' + option.dataset + '/LNTL' + '/' + option.exp_name\n","        if not os.path.exists(path):\n","            os.makedirs(path)\n","    \n","    return path\n","\n","\n","def backend_setting(option):\n","    # log_dir = os.path.join(option.save_dir, option.exp_name)\n","    # if not os.path.exists(log_dir):\n","    #     os.makedirs(log_dir)\n","\n","    if option.random_seed is None:\n","        option.random_seed = random.randint(1,10000)\n","    torch.manual_seed(option.random_seed)\n","\n","    if torch.cuda.is_available() and not option.cuda:\n","        print('WARNING: GPU is available, but we are not using it')\n","\n","    if not torch.cuda.is_available() and option.cuda:\n","        option.cuda = False\n","        print('Warning: Youve asked for CUDA but no GPU is available...setting CUDA to False')\n","\n","    if option.cuda:\n","        os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'\n","        #os.environ['CUDA_VISIBLE_DEVICES'] = ','.join([str(i) for i in option.gpu_ids])\n","        torch.cuda.manual_seed_all(option.random_seed)\n","        cudnn.benchmark = option.cudnn_benchmark\n","    \n","    if option.train_baseline:\n","        option.is_train = True\n","\n","\n","def main():\n","    #option = get_option()\n","    option = args\n","    #debug:\n","    #print(option)\n","    \n","    path = log_file_setup(option)\n","    backend_setting(option)\n","    trainer = Trainer(option, path)\n","\n","    train_dataset = DatasetTrain(option)\n","    val_dataset = DatasetVal(option)\n","\n","\n","    train_loader = torch.utils.data.DataLoader(dataset = train_dataset,\n","                                                batch_size=option.batch_size,\n","                                                shuffle=True,\n","                                                num_workers=option.num_workers)\n","\n","    val_loader = torch.utils.data.DataLoader(dataset = val_dataset,\n","                                                batch_size=option.batch_size,\n","                                                shuffle=False,\n","                                                num_workers=option.num_workers)\n","\n","    if option.is_train:   \n","        save_option(option, path)\n","        trainer.train(train_loader = train_loader, val_loader = val_loader)\n","    else:\n","        trainer._validate(trainval_loader) # I dont think we need this\n","\n","        pass\n","\n","if __name__ == '__main__': main()"],"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"R1z2lroAMnIv","executionInfo":{"status":"ok","timestamp":1627526520138,"user_tz":-60,"elapsed":5,"user":{"displayName":"Jack Stelling","photoUrl":"","userId":"10755116166180930038"}}},"source":["# # check the pickle file to see contents\n","\n","# import pandas as pd\n","\n","# lister = pd.read_pickle(r'/content/drive/MyDrive/BiasMitigation/LNTL/training_logs/Deeplab/Cityscapes/baseline/colour/Exp1_Stage1/epoch_losses_train.pkl')\n","# print(lister)"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"2jMgfJxQWJn6","executionInfo":{"status":"ok","timestamp":1627526520138,"user_tz":-60,"elapsed":4,"user":{"displayName":"Jack Stelling","photoUrl":"","userId":"10755116166180930038"}}},"source":["# lister = pd.read_pickle(r'/content/drive/MyDrive/Deeplabv3Flat/training_logs/model_1/epoch_losses_train.pkl')\n","# print(lister)"],"execution_count":5,"outputs":[]}]}