{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"colab":{"name":"segnet.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"code","metadata":{"id":"ZPnLf4NNq6y7"},"source":["\"\"\"\n","Pytorch implementation of SegNet (https://arxiv.org/pdf/1511.00561.pdf)\n","\"\"\"\n","\n","from __future__ import print_function\n","from collections import OrderedDict\n","import torch\n","import torch.nn as nn\n","import torchvision.models as models\n","import pprint\n","import torch.nn.functional as F\n","\n","import os\n","\n","\n","#F = nn.functional\n","DEBUG = False\n","\n","\n","vgg16_dims = [\n","                    (64, 64, 'M'),                                # Stage - 1\n","                    (128, 128, 'M'),                              # Stage - 2\n","                    (256, 256, 256,'M'),                          # Stage - 3\n","                    (512, 512, 512, 'M'),                         # Stage - 4\n","                    (512, 512, 512, 'M')                          # Stage - 5\n","            ]\n","\n","decoder_dims = [\n","                    ('U', 512, 512, 512),                         # Stage - 5\n","                    ('U', 512, 512, 512),                         # Stage - 4\n","                    ('U', 256, 256, 256),                         # Stage - 3\n","                    ('U', 128, 128),                              # Stage - 2\n","                    ('U', 64, 64)                                 # Stage - 1\n","                ]\n","\n","\n","class SegNet(nn.Module):\n","    def __init__(self):\n","        super(SegNet, self).__init__()\n","\n","        self.num_classes = 20\n","        self.input_channels = 3 # Always RGB, even Greyscale has grey values duplicated along 3 channels\n","\n","\n","        self.vgg16 = models.vgg16(pretrained=True) #load in a pretrained vgg16\n","        print('Pretrained VGG16 loaded for SegNet!')\n","\n","        # Encoder layers\n","\n","        self.encoder_conv_00 = nn.Sequential(*[\n","                                                nn.Conv2d(in_channels=self.input_channels,\n","                                                          out_channels=64,\n","                                                          kernel_size=3,\n","                                                          padding=1),\n","                                                nn.BatchNorm2d(64)\n","                                                ])\n","        self.encoder_conv_01 = nn.Sequential(*[\n","                                                nn.Conv2d(in_channels=64,\n","                                                          out_channels=64,\n","                                                          kernel_size=3,\n","                                                          padding=1),\n","                                                nn.BatchNorm2d(64)\n","                                                ])\n","        self.encoder_conv_10 = nn.Sequential(*[\n","                                                nn.Conv2d(in_channels=64,\n","                                                          out_channels=128,\n","                                                          kernel_size=3,\n","                                                          padding=1),\n","                                                nn.BatchNorm2d(128)\n","                                                ])\n","        self.encoder_conv_11 = nn.Sequential(*[\n","                                                nn.Conv2d(in_channels=128,\n","                                                          out_channels=128,\n","                                                          kernel_size=3,\n","                                                          padding=1),\n","                                                nn.BatchNorm2d(128)\n","                                                ])\n","        self.encoder_conv_20 = nn.Sequential(*[\n","                                                nn.Conv2d(in_channels=128,\n","                                                          out_channels=256,\n","                                                          kernel_size=3,\n","                                                          padding=1),\n","                                                nn.BatchNorm2d(256)\n","                                                ])\n","        self.encoder_conv_21 = nn.Sequential(*[\n","                                                nn.Conv2d(in_channels=256,\n","                                                          out_channels=256,\n","                                                          kernel_size=3,\n","                                                          padding=1),\n","                                                nn.BatchNorm2d(256)\n","                                                ])\n","        self.encoder_conv_22 = nn.Sequential(*[\n","                                                nn.Conv2d(in_channels=256,\n","                                                          out_channels=256,\n","                                                          kernel_size=3,\n","                                                          padding=1),\n","                                                nn.BatchNorm2d(256)\n","                                                ])\n","        self.encoder_conv_30 = nn.Sequential(*[\n","                                                nn.Conv2d(in_channels=256,\n","                                                          out_channels=512,\n","                                                          kernel_size=3,\n","                                                          padding=1),\n","                                                nn.BatchNorm2d(512)\n","                                                ])\n","        self.encoder_conv_31 = nn.Sequential(*[\n","                                                nn.Conv2d(in_channels=512,\n","                                                          out_channels=512,\n","                                                          kernel_size=3,\n","                                                          padding=1),\n","                                                nn.BatchNorm2d(512)\n","                                                ])\n","        self.encoder_conv_32 = nn.Sequential(*[\n","                                                nn.Conv2d(in_channels=512,\n","                                                          out_channels=512,\n","                                                          kernel_size=3,\n","                                                          padding=1),\n","                                                nn.BatchNorm2d(512)\n","                                                ])\n","        self.encoder_conv_40 = nn.Sequential(*[\n","                                                nn.Conv2d(in_channels=512,\n","                                                          out_channels=512,\n","                                                          kernel_size=3,\n","                                                          padding=1),\n","                                                nn.BatchNorm2d(512)\n","                                                ])\n","        self.encoder_conv_41 = nn.Sequential(*[\n","                                                nn.Conv2d(in_channels=512,\n","                                                          out_channels=512,\n","                                                          kernel_size=3,\n","                                                          padding=1),\n","                                                nn.BatchNorm2d(512)\n","                                                ])\n","        self.encoder_conv_42 = nn.Sequential(*[\n","                                                nn.Conv2d(in_channels=512,\n","                                                          out_channels=512,\n","                                                          kernel_size=3,\n","                                                          padding=1),\n","                                                nn.BatchNorm2d(512)\n","                                                ])\n","\n","        self.init_vgg_weigts()\n","\n","        # Decoder layers\n","\n","        self.decoder_convtr_42 = nn.Sequential(*[\n","                                                nn.ConvTranspose2d(in_channels=512,\n","                                                                   out_channels=512,\n","                                                                   kernel_size=3,\n","                                                                   padding=1),\n","                                                nn.BatchNorm2d(512)\n","                                               ])\n","        self.decoder_convtr_41 = nn.Sequential(*[\n","                                                nn.ConvTranspose2d(in_channels=512,\n","                                                                   out_channels=512,\n","                                                                   kernel_size=3,\n","                                                                   padding=1),\n","                                                nn.BatchNorm2d(512)\n","                                               ])\n","        self.decoder_convtr_40 = nn.Sequential(*[\n","                                                nn.ConvTranspose2d(in_channels=512,\n","                                                                   out_channels=512,\n","                                                                   kernel_size=3,\n","                                                                   padding=1),\n","                                                nn.BatchNorm2d(512)\n","                                               ])\n","        self.decoder_convtr_32 = nn.Sequential(*[\n","                                                nn.ConvTranspose2d(in_channels=512,\n","                                                                   out_channels=512,\n","                                                                   kernel_size=3,\n","                                                                   padding=1),\n","                                                nn.BatchNorm2d(512)\n","                                               ])\n","        self.decoder_convtr_31 = nn.Sequential(*[\n","                                                nn.ConvTranspose2d(in_channels=512,\n","                                                                   out_channels=512,\n","                                                                   kernel_size=3,\n","                                                                   padding=1),\n","                                                nn.BatchNorm2d(512)\n","                                               ])\n","        self.decoder_convtr_30 = nn.Sequential(*[\n","                                                nn.ConvTranspose2d(in_channels=512,\n","                                                                   out_channels=256,\n","                                                                   kernel_size=3,\n","                                                                   padding=1),\n","                                                nn.BatchNorm2d(256)\n","                                               ])\n","        self.decoder_convtr_22 = nn.Sequential(*[\n","                                                nn.ConvTranspose2d(in_channels=256,\n","                                                                   out_channels=256,\n","                                                                   kernel_size=3,\n","                                                                   padding=1),\n","                                                nn.BatchNorm2d(256)\n","                                               ])\n","        self.decoder_convtr_21 = nn.Sequential(*[\n","                                                nn.ConvTranspose2d(in_channels=256,\n","                                                                   out_channels=256,\n","                                                                   kernel_size=3,\n","                                                                   padding=1),\n","                                                nn.BatchNorm2d(256)\n","                                               ])\n","        self.decoder_convtr_20 = nn.Sequential(*[\n","                                                nn.ConvTranspose2d(in_channels=256,\n","                                                                   out_channels=128,\n","                                                                   kernel_size=3,\n","                                                                   padding=1),\n","                                                nn.BatchNorm2d(128)\n","                                               ])\n","        self.decoder_convtr_11 = nn.Sequential(*[\n","                                                nn.ConvTranspose2d(in_channels=128,\n","                                                                   out_channels=128,\n","                                                                   kernel_size=3,\n","                                                                   padding=1),\n","                                                nn.BatchNorm2d(128)\n","                                               ])\n","        self.decoder_convtr_10 = nn.Sequential(*[\n","                                                nn.ConvTranspose2d(in_channels=128,\n","                                                                   out_channels=64,\n","                                                                   kernel_size=3,\n","                                                                   padding=1),\n","                                                nn.BatchNorm2d(64)\n","                                               ])\n","        self.decoder_convtr_01 = nn.Sequential(*[\n","                                                nn.ConvTranspose2d(in_channels=64,\n","                                                                   out_channels=64,\n","                                                                   kernel_size=3,\n","                                                                   padding=1),\n","                                                nn.BatchNorm2d(64)\n","                                               ])\n","        self.decoder_convtr_00 = nn.Sequential(*[\n","                                                nn.ConvTranspose2d(in_channels=64,\n","                                                                   out_channels=self.num_classes,\n","                                                                   kernel_size=3,\n","                                                                   padding=1)\n","                                               ])\n","\n","\n","    def forward(self, input_img):\n","        \"\"\"\n","        Forward pass `input_img` through the network\n","        \"\"\"\n","\n","        # Encoder\n","\n","        # Encoder Stage - 1\n","        dim_0 = input_img.size()\n","        x_00 = F.relu(self.encoder_conv_00(input_img))\n","        x_01 = F.relu(self.encoder_conv_01(x_00))\n","        x_0, indices_0 = F.max_pool2d(x_01, kernel_size=2, stride=2, return_indices=True)\n","\n","        # Encoder Stage - 2\n","        dim_1 = x_0.size()\n","        x_10 = F.relu(self.encoder_conv_10(x_0))\n","        x_11 = F.relu(self.encoder_conv_11(x_10))\n","        x_1, indices_1 = F.max_pool2d(x_11, kernel_size=2, stride=2, return_indices=True)\n","\n","        # Encoder Stage - 3\n","        dim_2 = x_1.size()\n","        x_20 = F.relu(self.encoder_conv_20(x_1))\n","        x_21 = F.relu(self.encoder_conv_21(x_20))\n","        x_22 = F.relu(self.encoder_conv_22(x_21))\n","        x_2, indices_2 = F.max_pool2d(x_22, kernel_size=2, stride=2, return_indices=True)\n","\n","        # Encoder Stage - 4\n","        dim_3 = x_2.size()\n","        x_30 = F.relu(self.encoder_conv_30(x_2))\n","        x_31 = F.relu(self.encoder_conv_31(x_30))\n","        x_32 = F.relu(self.encoder_conv_32(x_31))\n","        x_3, indices_3 = F.max_pool2d(x_32, kernel_size=2, stride=2, return_indices=True)\n","\n","        # Encoder Stage - 5\n","        dim_4 = x_3.size()\n","        x_40 = F.relu(self.encoder_conv_40(x_3))\n","        x_41 = F.relu(self.encoder_conv_41(x_40))\n","        x_42 = F.relu(self.encoder_conv_42(x_41))\n","        x_4, indices_4 = F.max_pool2d(x_42, kernel_size=2, stride=2, return_indices=True)\n","\n","        # Decoder\n","\n","        dim_d = x_4.size()\n","\n","        # Decoder Stage - 5\n","        x_4d = F.max_unpool2d(x_4, indices_4, kernel_size=2, stride=2, output_size=dim_4)\n","        x_42d = F.relu(self.decoder_convtr_42(x_4d))\n","        x_41d = F.relu(self.decoder_convtr_41(x_42d))\n","        x_40d = F.relu(self.decoder_convtr_40(x_41d))\n","        dim_4d = x_40d.size()\n","\n","        # Decoder Stage - 4\n","        x_3d = F.max_unpool2d(x_40d, indices_3, kernel_size=2, stride=2, output_size=dim_3)\n","        x_32d = F.relu(self.decoder_convtr_32(x_3d))\n","        x_31d = F.relu(self.decoder_convtr_31(x_32d))\n","        x_30d = F.relu(self.decoder_convtr_30(x_31d))\n","        dim_3d = x_30d.size()\n","\n","        # Decoder Stage - 3\n","        x_2d = F.max_unpool2d(x_30d, indices_2, kernel_size=2, stride=2, output_size=dim_2)\n","        x_22d = F.relu(self.decoder_convtr_22(x_2d))\n","        x_21d = F.relu(self.decoder_convtr_21(x_22d))\n","        x_20d = F.relu(self.decoder_convtr_20(x_21d))\n","        dim_2d = x_20d.size()\n","\n","        # Decoder Stage - 2\n","        x_1d = F.max_unpool2d(x_20d, indices_1, kernel_size=2, stride=2, output_size=dim_1)\n","        x_11d = F.relu(self.decoder_convtr_11(x_1d))\n","        x_10d = F.relu(self.decoder_convtr_10(x_11d))\n","        dim_1d = x_10d.size()\n","\n","        # ~~~ Bias fork insterted here\n","        bias_fork = x_10d  # Out channels = 64\n","        # ~~~\n","\n","        # Decoder Stage - 1\n","        x_0d = F.max_unpool2d(x_10d, indices_0, kernel_size=2, stride=2, output_size=dim_0)\n","        x_01d = F.relu(self.decoder_convtr_01(x_0d))\n","        x_00d = self.decoder_convtr_00(x_01d)\n","        dim_0d = x_00d.size()\n","\n","        x_softmax = F.softmax(x_00d, dim=1)\n","\n","\n","        if DEBUG:\n","            print(\"dim_0: {}\".format(dim_0))\n","            print(\"dim_1: {}\".format(dim_1))\n","            print(\"dim_2: {}\".format(dim_2))\n","            print(\"dim_3: {}\".format(dim_3))\n","            print(\"dim_4: {}\".format(dim_4))\n","\n","            print(\"dim_d: {}\".format(dim_d))\n","            print(\"dim_4d: {}\".format(dim_4d))\n","            print(\"dim_3d: {}\".format(dim_3d))\n","            print(\"dim_2d: {}\".format(dim_2d))\n","            print(\"dim_1d: {}\".format(dim_1d)) #<---- we've inserted bias fork here so need this size for the bias label as the bias head preserves spatial resolution\n","            print(\"dim_0d: {}\".format(dim_0d))\n","\n","            # dim_1d is 64 x 128 x 128 with cityscapes image after dataloading\n","\n","        return x_00d, x_softmax, bias_fork\n","\n","\n","    def init_vgg_weigts(self):\n","        assert self.encoder_conv_00[0].weight.size() == self.vgg16.features[0].weight.size()\n","        self.encoder_conv_00[0].weight.data = self.vgg16.features[0].weight.data\n","        assert self.encoder_conv_00[0].bias.size() == self.vgg16.features[0].bias.size()\n","        self.encoder_conv_00[0].bias.data = self.vgg16.features[0].bias.data\n","\n","        assert self.encoder_conv_01[0].weight.size() == self.vgg16.features[2].weight.size()\n","        self.encoder_conv_01[0].weight.data = self.vgg16.features[2].weight.data\n","        assert self.encoder_conv_01[0].bias.size() == self.vgg16.features[2].bias.size()\n","        self.encoder_conv_01[0].bias.data = self.vgg16.features[2].bias.data\n","\n","        assert self.encoder_conv_10[0].weight.size() == self.vgg16.features[5].weight.size()\n","        self.encoder_conv_10[0].weight.data = self.vgg16.features[5].weight.data\n","        assert self.encoder_conv_10[0].bias.size() == self.vgg16.features[5].bias.size()\n","        self.encoder_conv_10[0].bias.data = self.vgg16.features[5].bias.data\n","\n","        assert self.encoder_conv_11[0].weight.size() == self.vgg16.features[7].weight.size()\n","        self.encoder_conv_11[0].weight.data = self.vgg16.features[7].weight.data\n","        assert self.encoder_conv_11[0].bias.size() == self.vgg16.features[7].bias.size()\n","        self.encoder_conv_11[0].bias.data = self.vgg16.features[7].bias.data\n","\n","        assert self.encoder_conv_20[0].weight.size() == self.vgg16.features[10].weight.size()\n","        self.encoder_conv_20[0].weight.data = self.vgg16.features[10].weight.data\n","        assert self.encoder_conv_20[0].bias.size() == self.vgg16.features[10].bias.size()\n","        self.encoder_conv_20[0].bias.data = self.vgg16.features[10].bias.data\n","\n","        assert self.encoder_conv_21[0].weight.size() == self.vgg16.features[12].weight.size()\n","        self.encoder_conv_21[0].weight.data = self.vgg16.features[12].weight.data\n","        assert self.encoder_conv_21[0].bias.size() == self.vgg16.features[12].bias.size()\n","        self.encoder_conv_21[0].bias.data = self.vgg16.features[12].bias.data\n","\n","        assert self.encoder_conv_22[0].weight.size() == self.vgg16.features[14].weight.size()\n","        self.encoder_conv_22[0].weight.data = self.vgg16.features[14].weight.data\n","        assert self.encoder_conv_22[0].bias.size() == self.vgg16.features[14].bias.size()\n","        self.encoder_conv_22[0].bias.data = self.vgg16.features[14].bias.data\n","\n","        assert self.encoder_conv_30[0].weight.size() == self.vgg16.features[17].weight.size()\n","        self.encoder_conv_30[0].weight.data = self.vgg16.features[17].weight.data\n","        assert self.encoder_conv_30[0].bias.size() == self.vgg16.features[17].bias.size()\n","        self.encoder_conv_30[0].bias.data = self.vgg16.features[17].bias.data\n","\n","        assert self.encoder_conv_31[0].weight.size() == self.vgg16.features[19].weight.size()\n","        self.encoder_conv_31[0].weight.data = self.vgg16.features[19].weight.data\n","        assert self.encoder_conv_31[0].bias.size() == self.vgg16.features[19].bias.size()\n","        self.encoder_conv_31[0].bias.data = self.vgg16.features[19].bias.data\n","\n","        assert self.encoder_conv_32[0].weight.size() == self.vgg16.features[21].weight.size()\n","        self.encoder_conv_32[0].weight.data = self.vgg16.features[21].weight.data\n","        assert self.encoder_conv_32[0].bias.size() == self.vgg16.features[21].bias.size()\n","        self.encoder_conv_32[0].bias.data = self.vgg16.features[21].bias.data\n","\n","        assert self.encoder_conv_40[0].weight.size() == self.vgg16.features[24].weight.size()\n","        self.encoder_conv_40[0].weight.data = self.vgg16.features[24].weight.data\n","        assert self.encoder_conv_40[0].bias.size() == self.vgg16.features[24].bias.size()\n","        self.encoder_conv_40[0].bias.data = self.vgg16.features[24].bias.data\n","\n","        assert self.encoder_conv_41[0].weight.size() == self.vgg16.features[26].weight.size()\n","        self.encoder_conv_41[0].weight.data = self.vgg16.features[26].weight.data\n","        assert self.encoder_conv_41[0].bias.size() == self.vgg16.features[26].bias.size()\n","        self.encoder_conv_41[0].bias.data = self.vgg16.features[26].bias.data\n","\n","        assert self.encoder_conv_42[0].weight.size() == self.vgg16.features[28].weight.size()\n","        self.encoder_conv_42[0].weight.data = self.vgg16.features[28].weight.data\n","        assert self.encoder_conv_42[0].bias.size() == self.vgg16.features[28].bias.size()\n","        self.encoder_conv_42[0].bias.data = self.vgg16.features[28].bias.data"],"execution_count":null,"outputs":[]}]}