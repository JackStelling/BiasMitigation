{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"biashead.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyN5EYMaBryD2uMu/P3NAvqf"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"L9I-zP5_CvCw"},"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","\n","class BiasPredictor(nn.Module):\n","    def __init__(self, input_ch = 1280, num_classes = 8 ):\n","        super(BiasPredictor, self).__init__()\n","        self.pred_conv1 = nn.Conv2d(input_ch, input_ch, kernel_size=3,\n","                                    stride=1, padding=1) # these conv layers preserve spatital resolution kernel = 3x3. padding 1 and stride 1\n","        self.pred_bn1   = nn.BatchNorm2d(input_ch)\n","        self.relu       = nn.ReLU(inplace=True)\n","        self.pred_conv2 = nn.Conv2d(input_ch, num_classes, kernel_size=3,\n","                                    stride=1, padding=1)\n","        self.softmax    = nn.Softmax(dim=1)\n","\n","    def forward(self, x):\n","        print('x.shape....', x.shape)\n","        x = self.pred_conv1(x)\n","        x = self.pred_bn1(x)\n","        x = self.relu(x)\n","        print('x.shape....', x.shape)\n","        x = self.pred_conv2(x)\n","        px = self.softmax(x)\n","\n","        return x,px"],"execution_count":null,"outputs":[]}]}