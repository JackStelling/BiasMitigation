{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"utils_LNTL.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMSQlLZx0iN6AtI6RTnuIPi"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"9snjwCNuBSmR"},"source":["# -*- coding: utf-8 -*-\n","import os\n","import json\n","import time\n","import logging\n","import numpy as np \n","import torch \n","\n","def save_option(option, path):\n","    option_path = os.path.join(path, \"options.json\")\n","\n","    with open(option_path, 'w') as fp:\n","        json.dump(option.__dict__, fp, indent=4, sort_keys=True)\n","\n","def logger_setting(exp_name, save_dir, path, debug):\n","    logger = logging.getLogger(exp_name)\n","    formatter = logging.Formatter('[%(name)s] %(levelname)s: %(message)s')\n","\n","    log_out = os.path.join(path, 'train.log')\n","    file_handler = logging.FileHandler(log_out)\n","    stream_handler = logging.StreamHandler()\n","\n","    file_handler.setFormatter(formatter)\n","    stream_handler.setFormatter(formatter)\n","\n","    logger.addHandler(file_handler)\n","    logger.addHandler(stream_handler)\n","\n","    if debug:\n","        logger.setLevel(logging.DEBUG)\n","    else:\n","        logger.setLevel(logging.INFO)\n","    return logger\n","\n","class Timer(object):\n","    def __init__(self, logger, max_step, last_step=0):\n","        self.logger = logger\n","        self.max_step = max_step\n","        self.step = last_step\n","\n","        curr_time = time.time()\n","        self.start = curr_time\n","        self.last = curr_time\n","\n","    def __call__(self):\n","        curr_time = time.time()\n","        self.step += 1\n","\n","        duration = curr_time - self.last\n","        remaining = (self.max_step - self.step) * (curr_time - self.start) / self.step / 3600\n","        msg = 'TIMER, duration(s)|remaining(h), %f, %f' % (duration, remaining)\n","\n","        self.last = curr_time\n","\n","# The following methods are used saving the images of the dataloaders in the \n","# trainer_merger script see them in action in the /helpers folder:\n","\n","def bias_label_interpretation(bias_label):\n","        \n","    label = bias_label[0].clone().detach().numpy()\n","\n","    label_trans = (label*32)+16\n","    label_trans = label_trans.astype(np.uint8)\n","\n","    b = label_trans.astype(np.uint8)\n","    b=b.transpose(1, 2, 0) #change to W x H x C\n","\n","    # set green and red channels to 0\n","    b[:, :, 1] = 0\n","    b[:, :, 2] = 0\n","    \n","    g = label_trans.astype(np.uint8)\n","    g=g.transpose(1, 2, 0)\n","    # set blue and red channels to 0\n","    g[:, :, 0] = 0\n","    g[:, :, 2] = 0\n","\n","    r = label_trans.astype(np.uint8)\n","    r=r.transpose(1, 2, 0)\n","    # set blue and green channels to 0\n","    r[:, :, 0] = 0\n","    r[:, :, 1] = 0\n","    \n","    return label_trans, r, g, b\n","\n","def un_normalise_image(image):\n","    # reverse the steps of the normalisation at the end of the dataloader script:\n","    test_imgs = image[0].cpu().detach().numpy()\n","    #print(test_imgs.shape)\n","    test_imgs = np.transpose(test_imgs, (1, 2, 0)) #inverse transpose\n","    #print(test_imgs.shape)\n","    test_imgs = test_imgs * np.array([0.229, 0.224, 0.225])\n","    #print(test_imgs.shape)\n","    test_imgs = test_imgs + np.array([0.485, 0.456, 0.406])\n","    #print(test_imgs.shape)\n","    test_imgs = test_imgs*255\n","\n","    return test_imgs\n","\n","def detach_transpose_labels(label):\n","    #print(label.shape)\n","    test_label = label[0].cpu().detach().numpy()\n","    #print(test_label.shape)\n","\n","    return test_label"],"execution_count":null,"outputs":[]}]}