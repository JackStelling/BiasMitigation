{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from datasets.ipynb\n",
      "importing Jupyter notebook from deeplabv3.ipynb\n",
      "importing Jupyter notebook from resnet.ipynb\n",
      "importing Jupyter notebook from aspp.ipynb\n",
      "importing Jupyter notebook from utils.ipynb\n",
      "pretrained resnet, 18\n",
      "num_train_batches: 991\n",
      "num_val_batches: 166\n",
      "###########################\n",
      "######## NEW EPOCH ########\n",
      "###########################\n",
      "epoch: 1/100\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import sys\n",
    "\n",
    "# this next import comes from within our file structure (our datasets script)\n",
    "import import_ipynb\n",
    "from datasets import DatasetTrain, DatasetVal # (this needs to be imported before torch, because cv2 needs to be imported before torch for some reason)\n",
    "#import os\n",
    "\n",
    "#cwd = 'C:/Users/Lenovo/Documents/Thesis/Code/DeepLabv3'\n",
    "\n",
    "#os.chdir('C:/Users/Lenovo/Documents/Thesis/Code/DeepLabv3Flat/model')\n",
    "#sys.path.append(\"C:/Users/Lenovo/Documents/Thesis/Code/DeepLabv3Flat/model\")\n",
    "from deeplabv3 import DeepLabV3\n",
    "\n",
    "#os.chdir('C:/Users/Lenovo/Documents/Thesis/Code/DeepLabv3Flat/utils')\n",
    "#sys.path.append(\"C:/Users/Lenovo/Documents/Thesis/Code/DeepLabv3Flat/utils\")\n",
    "from utils import add_weight_decay\n",
    "\n",
    "#os.chdir(cwd)\n",
    "\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# NOTE! NOTE! change this to not overwrite all log data when you train the model:\n",
    "model_id = \"1\"\n",
    "\n",
    "num_epochs = 100\n",
    "batch_size = 3\n",
    "learning_rate = 0.0001\n",
    "\n",
    "network = DeepLabV3(model_id, project_dir=\"C:/Users/Lenovo/Documents/Thesis/Code/DeepLabv3Flat\").cuda()\n",
    "\n",
    "train_dataset = DatasetTrain(cityscapes_data_path=\"C:/Users/Lenovo/Documents/Thesis/Datasets/CityScapes\",\n",
    "                             cityscapes_meta_path=\"C:/Users/Lenovo/Documents/Thesis/Datasets/CityScapes/meta\")\n",
    "val_dataset = DatasetVal(cityscapes_data_path=\"C:/Users/Lenovo/Documents/Thesis/Datasets/CityScapes\",\n",
    "                         cityscapes_meta_path=\"C:/Users/Lenovo/Documents/Thesis/Datasets/CityScapes/meta\")\n",
    "\n",
    "num_train_batches = int(len(train_dataset)/batch_size)\n",
    "num_val_batches = int(len(val_dataset)/batch_size)\n",
    "print (\"num_train_batches:\", num_train_batches)\n",
    "print (\"num_val_batches:\", num_val_batches)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size, shuffle=True,\n",
    "                                           num_workers=1)\n",
    "val_loader = torch.utils.data.DataLoader(dataset=val_dataset,\n",
    "                                         batch_size=batch_size, shuffle=False,\n",
    "                                         num_workers=1)\n",
    "\n",
    "params = add_weight_decay(network, l2_value=0.0001)\n",
    "optimizer = torch.optim.Adam(params, lr=learning_rate)\n",
    "\n",
    "with open(\"C:/Users/Lenovo/Documents/Thesis/Datasets/CityScapes/meta/class_weights.pkl\", \"rb\") as file: # (needed for python3)\n",
    "    class_weights = np.array(pickle.load(file))\n",
    "class_weights = torch.from_numpy(class_weights)\n",
    "class_weights = Variable(class_weights.type(torch.FloatTensor)).cuda()\n",
    "\n",
    "# loss function\n",
    "loss_fn = nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "epoch_losses_train = []\n",
    "epoch_losses_val = []\n",
    "for epoch in range(num_epochs):\n",
    "    print (\"###########################\")\n",
    "    print (\"######## NEW EPOCH ########\")\n",
    "    print (\"###########################\")\n",
    "    print (\"epoch: %d/%d\" % (epoch+1, num_epochs))\n",
    "\n",
    "    ############################################################################\n",
    "    # train:\n",
    "    ############################################################################\n",
    "    network.train() # (set in training mode, this affects BatchNorm and dropout)\n",
    "    batch_losses = []\n",
    "    \n",
    "    # found this from aladdin person youtube 'add progress bar to pytorch'\n",
    "    loop = tqdm(enumerate(train_loader), total=len(train_loader), leave=False)\n",
    "    \n",
    "    for step, (imgs, label_imgs) in loop:\n",
    "        current_time = time.time()\n",
    "\n",
    "        imgs = Variable(imgs).cuda() # (shape: (batch_size, 3, img_h, img_w))\n",
    "        label_imgs = Variable(label_imgs.type(torch.LongTensor)).cuda() # (shape: (batch_size, img_h, img_w))\n",
    "\n",
    "        outputs = network(imgs) # (shape: (batch_size, num_classes, img_h, img_w))\n",
    "\n",
    "        # compute the loss:\n",
    "        loss = loss_fn(outputs, label_imgs)\n",
    "        loss_value = loss.data.cpu().numpy()\n",
    "        batch_losses.append(loss_value)\n",
    "\n",
    "        # optimization step:\n",
    "        optimizer.zero_grad() # (reset gradients)\n",
    "        loss.backward() # (compute gradients)\n",
    "        optimizer.step() # (perform optimization step)\n",
    "\n",
    "        print (time.time() - current_time)\n",
    "\n",
    "    epoch_loss = np.mean(batch_losses)\n",
    "    epoch_losses_train.append(epoch_loss)\n",
    "    with open(\"%s/epoch_losses_train.pkl\" % network.model_dir, \"wb\") as file:\n",
    "        pickle.dump(epoch_losses_train, file)\n",
    "    print (\"train loss: %g\" % epoch_loss)\n",
    "    plt.figure(1)\n",
    "    plt.plot(epoch_losses_train, \"k^\")\n",
    "    plt.plot(epoch_losses_train, \"k\")\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.title(\"train loss per epoch\")\n",
    "    plt.savefig(\"%s/epoch_losses_train.png\" % network.model_dir)\n",
    "    plt.close(1)\n",
    "\n",
    "    print (\"####\")\n",
    "\n",
    "    # Update Progress Bar\n",
    "    loop.set_description(f\"Epoch [{epoch}/{num_epochs}]\")\n",
    "    loop.set_postfix(loss = loss.item())\n",
    "    \n",
    "    \n",
    "    ############################################################################\n",
    "    # val:\n",
    "    ############################################################################\n",
    "    network.eval() # (set in evaluation mode, this affects BatchNorm and dropout)\n",
    "    batch_losses = []\n",
    "    for step, (imgs, label_imgs, img_ids) in enumerate(val_loader):\n",
    "        with torch.no_grad(): # (corresponds to setting volatile=True in all variables, this is done during inference to reduce memory consumption)\n",
    "            imgs = Variable(imgs).cuda() # (shape: (batch_size, 3, img_h, img_w))\n",
    "            label_imgs = Variable(label_imgs.type(torch.LongTensor)).cuda() # (shape: (batch_size, img_h, img_w))\n",
    "\n",
    "            outputs = network(imgs) # (shape: (batch_size, num_classes, img_h, img_w))\n",
    "\n",
    "            # compute the loss:\n",
    "            loss = loss_fn(outputs, label_imgs)\n",
    "            loss_value = loss.data.cpu().numpy()\n",
    "            batch_losses.append(loss_value)\n",
    "\n",
    "    epoch_loss = np.mean(batch_losses)\n",
    "    epoch_losses_val.append(epoch_loss)\n",
    "    with open(\"%s/epoch_losses_val.pkl\" % network.model_dir, \"wb\") as file:\n",
    "        pickle.dump(epoch_losses_val, file)\n",
    "    print (\"val loss: %g\" % epoch_loss)\n",
    "    plt.figure(1)\n",
    "    plt.plot(epoch_losses_val, \"k^\")\n",
    "    plt.plot(epoch_losses_val, \"k\")\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.title(\"val loss per epoch\")\n",
    "    plt.savefig(\"%s/epoch_losses_val.png\" % network.model_dir)\n",
    "    plt.close(1)\n",
    "\n",
    "    # save the model weights to disk:\n",
    "    checkpoint_path = network.checkpoints_dir + \"/model_\" + model_id +\"_epoch_\" + str(epoch+1) + \".pth\"\n",
    "    torch.save(network.state_dict(), checkpoint_path)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints', 'utils.ipynb']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()\n",
    "\n",
    "os.listdir(os.getcwd())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
