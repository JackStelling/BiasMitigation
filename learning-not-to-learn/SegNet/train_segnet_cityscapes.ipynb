{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"train_segnet_cityscapes.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"widgets":{"application/vnd.jupyter.widget-state+json":{"1287b5ff16054e6880bb0032871e3494":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_c984341cfa4e4d1c8549bda09bd454e2","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_5c96871942ee4a02b0518c6a980e8eb5","IPY_MODEL_5878bee842fd42c6a8d735db7a036260"]}},"c984341cfa4e4d1c8549bda09bd454e2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5c96871942ee4a02b0518c6a980e8eb5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_da3983a71bab4b64bdf0e89f88c729c2","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":553433881,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":553433881,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_518af4c414214a09888edad7c9edc626"}},"5878bee842fd42c6a8d735db7a036260":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_df111312c3e84c8a81a62cc3fd99cb21","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"â€‹","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 528M/528M [1:02:26&lt;00:00, 148kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3ba19b2de4a7487f930fcc51c23e7c0d"}},"da3983a71bab4b64bdf0e89f88c729c2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"518af4c414214a09888edad7c9edc626":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"df111312c3e84c8a81a62cc3fd99cb21":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"3ba19b2de4a7487f930fcc51c23e7c0d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m35YA_bwDHQ-","executionInfo":{"status":"ok","timestamp":1625265963201,"user_tz":-60,"elapsed":25315,"user":{"displayName":"Jack Stelling","photoUrl":"","userId":"10755116166180930038"}},"outputId":"9ad0b72a-dea7-4da8-cd1f-97cae4172101"},"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","#drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dwOOFoanDQQC","executionInfo":{"status":"ok","timestamp":1625265970667,"user_tz":-60,"elapsed":808,"user":{"displayName":"Jack Stelling","photoUrl":"","userId":"10755116166180930038"}},"outputId":"642a86a3-5620-4162-fb4c-3117fe19c4ee"},"source":["import os \n","\n","os.getcwd()\n","\n","#os.listdir('/content/drive/MyDrive/SegNet')\n","#os.listdir('/content/drive/MyDrive/Datasets')\n","\n","os.chdir('/content/drive/MyDrive/SegNet')\n","print('Directory Changed')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Directory Changed\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["1287b5ff16054e6880bb0032871e3494","c984341cfa4e4d1c8549bda09bd454e2","5c96871942ee4a02b0518c6a980e8eb5","5878bee842fd42c6a8d735db7a036260","da3983a71bab4b64bdf0e89f88c729c2","518af4c414214a09888edad7c9edc626","df111312c3e84c8a81a62cc3fd99cb21","3ba19b2de4a7487f930fcc51c23e7c0d"],"output_embedded_package_id":"1-kLKfgEQn0-FVjhOoR88KgA7rR5OdXT6"},"id":"T9J68xfeFVU1","executionInfo":{"status":"error","timestamp":1625298823455,"user_tz":-60,"elapsed":32837723,"user":{"displayName":"Jack Stelling","photoUrl":"","userId":"10755116166180930038"}},"outputId":"046d9fe0-37c6-4dbb-adf6-f787eab0871a"},"source":["\n","import sys\n","\n","# this next import comes from within our file structure (our datasets script)\n","! pip install import-ipynb \n","import import_ipynb\n","from datasets import DatasetTrain, DatasetVal # (this needs to be imported before torch, because cv2 needs to be imported before torch for some reason)\n","# import os\n","\n","# Mount a file stored on Google Drive:\n","#from google.colab import drive\n","#drive.mount('/content/drive/MyDrive/Deeplabv3Flat') \n","#Use code block at the top of page\n","\n","\n","# Dont need these commented out lines on Colab. File structutre is flat\n","#cwd = '/content/drive/MyDrive/Deeplabv3Flat'\n","\n","#os.chdir('/content/drive/MyDrive/Deeplabv3Flat/model')\n","#sys.path.append(\"/content/drive/MyDrive/Deeplabv3Flat/model\")\n","from segnet import SegNet\n","\n","#os.chdir('/content/drive/MyDrive/Deeplabv3Flat/utils')\n","#sys.path.append(\"/content/drive/MyDrive/Deeplabv3Flat/utils\")\n","from utils import add_weight_decay\n","\n","#os.chdir(cwd)\n","\n","import torch\n","import torch.utils.data\n","import torch.nn as nn\n","from torch.autograd import Variable\n","import torch.optim as optim\n","import torch.nn.functional as F\n","\n","import numpy as np\n","import pickle\n","import matplotlib\n","matplotlib.use(\"Agg\")\n","import matplotlib.pyplot as plt\n","import cv2\n","\n","import time\n","from tqdm import tqdm\n","\n","\n","# NOTE! NOTE! change this to not overwrite all log data when you train the model:\n","model_id = \"1\"\n","\n","# Constants\n","NUM_INPUT_CHANNELS = 3  # We may need to change this when doing greyscale baselines later. \n","#NUM_OUTPUT_CHANNELS = NUM_CLASSES\n","\n","num_epochs = 100\n","batch_size = 8   # changed from 3 to 24 to 16 to 8. 24 and 16 gave OOM errors. \n","learning_rate = 0.0001\n","\n","network = SegNet(model_id, project_dir=\"/content/drive/MyDrive/SegNet\", input_channels=NUM_INPUT_CHANNELS).cuda()\n","\n","# Amirs suggestion to resume training from last checkpoint #\n","\n","resume = False #change this flag if starting from scratch \n","\n","if resume == True:\n","     network.load_state_dict(torch.load(\"/content/drive/MyDrive/SegNet/training_logs/model_3/checkpoints/model_3_epoch_100.pth\"))\n","\n","#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n","\n","\n","train_dataset = DatasetTrain(cityscapes_data_path=\"/content/drive/MyDrive/Datasets/Cityscapes\",\n","                             cityscapes_meta_path=\"/content/drive/MyDrive/Datasets/Cityscapes/meta\")\n","val_dataset = DatasetVal(cityscapes_data_path=\"/content/drive/MyDrive/Datasets/Cityscapes\",\n","                         cityscapes_meta_path=\"/content/drive/MyDrive/Datasets/Cityscapes/meta\")\n","\n","num_train_batches = int(len(train_dataset)/batch_size)\n","num_val_batches = int(len(val_dataset)/batch_size)\n","print (\"num_train_batches:\", num_train_batches)\n","print (\"num_val_batches:\", num_val_batches)\n","\n","train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n","                                           batch_size=batch_size, shuffle=True,\n","                                           num_workers=2) #changed from 1 to 4 then warning suggested a max of 2 so the dataloaders dont freeze ## as below \n","val_loader = torch.utils.data.DataLoader(dataset=val_dataset,\n","                                         batch_size=batch_size, shuffle=False,\n","                                         num_workers=2) # as above\n","\n","params = add_weight_decay(network, l2_value=0.0001)\n","optimizer = torch.optim.Adam(params, lr=learning_rate)\n","\n","with open(\"/content/drive/MyDrive/Datasets/Cityscapes/meta/class_weights.pkl\", \"rb\") as file: # (needed for python3)\n","    class_weights = np.array(pickle.load(file))\n","class_weights = torch.from_numpy(class_weights)\n","class_weights = Variable(class_weights.type(torch.FloatTensor)).cuda()\n","\n","# loss function\n","loss_fn = nn.CrossEntropyLoss(weight=class_weights)\n","\n","epoch_losses_train = []\n","epoch_losses_val = []\n","for epoch in range(num_epochs):\n","    print (\"###########################\")\n","    print (\"######## NEW EPOCH ########\")\n","    print (\"###########################\")\n","    print (\"epoch: %d/%d\" % (epoch+1, num_epochs))\n","\n","    ############################################################################\n","    # train:\n","    ############################################################################\n","    network.train() # (set in training mode, this affects BatchNorm and dropout)\n","    batch_losses = []\n","    \n","    # found this from aladdin person youtube 'add progress bar to pytorch'\n","    loop = tqdm(enumerate(train_loader), total=len(train_loader), leave=False)\n","    \n","    for step, (imgs, label_imgs) in loop:\n","        current_time = time.time()\n","\n","        imgs = Variable(imgs).cuda() # (shape: (batch_size, 3, img_h, img_w))\n","        label_imgs = Variable(label_imgs.type(torch.LongTensor)).cuda() # (shape: (batch_size, img_h, img_w))\n","\n","        #outputs = network(imgs) # (shape: (batch_size, num_classes, img_h, img_w))\n","        #predicted_tensor, softmaxed_tensor = model(input_tensor)\n","        predicted_tensor, softmaxed_tensor = network(imgs)  # Because the SegNet class gives two outputs\n","        \n","        # compute the loss:\n","        loss = loss_fn(predicted_tensor, label_imgs)\n","        loss_value = loss.data.cpu().numpy()\n","        batch_losses.append(loss_value)\n","\n","        # optimization step:\n","        optimizer.zero_grad() # (reset gradients)\n","        loss.backward() # (compute gradients)\n","        optimizer.step() # (perform optimization step)\n","\n","        # Update Progress Bar\n","        loop.set_description(f\"Epoch [{epoch+1}/{num_epochs}]\")\n","        loop.set_postfix(loss = loss.item())\n","        print (time.time() - current_time)\n","\n","    epoch_loss = np.mean(batch_losses)\n","    epoch_losses_train.append(epoch_loss)\n","    with open(\"%s/epoch_losses_train.pkl\" % network.model_dir, \"wb\") as file:\n","        pickle.dump(epoch_losses_train, file)\n","    print (\"train loss: %g\" % epoch_loss)\n","    plt.figure(1)\n","    plt.plot(epoch_losses_train, \"k^\")\n","    plt.plot(epoch_losses_train, \"k\")\n","    plt.ylabel(\"loss\")\n","    plt.xlabel(\"epoch\")\n","    plt.title(\"train loss per epoch\")\n","    plt.savefig(\"%s/epoch_losses_train.png\" % network.model_dir)\n","    plt.close(1)\n","\n","    print (\"####\")\n","\n","    \n","    \n","    ############################################################################\n","    # val:\n","    ############################################################################\n","    network.eval() # (set in evaluation mode, this affects BatchNorm and dropout)\n","    batch_losses = []\n","    for step, (imgs, label_imgs, img_ids) in enumerate(val_loader):\n","        with torch.no_grad(): # (corresponds to setting volatile=True in all variables, this is done during inference to reduce memory consumption)\n","            imgs = Variable(imgs).cuda() # (shape: (batch_size, 3, img_h, img_w))\n","            label_imgs = Variable(label_imgs.type(torch.LongTensor)).cuda() # (shape: (batch_size, img_h, img_w))\n","\n","            #outputs = network(imgs) # (shape: (batch_size, num_classes, img_h, img_w))\n","            predicted_tensor, softmaxed_tensor = network(imgs)\n","\n","            # compute the loss:\n","            loss = loss_fn(predicted_tensor, label_imgs)\n","            loss_value = loss.data.cpu().numpy()\n","            batch_losses.append(loss_value)\n","\n","    epoch_loss = np.mean(batch_losses)\n","    epoch_losses_val.append(epoch_loss)\n","    with open(\"%s/epoch_losses_val.pkl\" % network.model_dir, \"wb\") as file:\n","        pickle.dump(epoch_losses_val, file)\n","    print (\"val loss: %g\" % epoch_loss)\n","    plt.figure(1)\n","    plt.plot(epoch_losses_val, \"k^\")\n","    plt.plot(epoch_losses_val, \"k\")\n","    plt.ylabel(\"loss\")\n","    plt.xlabel(\"epoch\")\n","    plt.title(\"val loss per epoch\")\n","    plt.savefig(\"%s/epoch_losses_val.png\" % network.model_dir)\n","    plt.close(1)\n","\n","    # save the model weights to disk:\n","    checkpoint_path = network.checkpoints_dir + \"/model_\" + model_id +\"_epoch_\" + str(epoch+1) + \".pth\"\n","    torch.save(network.state_dict(), checkpoint_path)\n","    \n","    "],"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]}]}