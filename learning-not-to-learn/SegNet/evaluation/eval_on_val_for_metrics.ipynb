{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"colab":{"name":"eval_on_val_for_metrics.ipynb","provenance":[]},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"bkplk8GlS_lj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623337547064,"user_tz":-60,"elapsed":22438,"user":{"displayName":"Jack Stelling","photoUrl":"","userId":"10755116166180930038"}},"outputId":"4883ae9a-2690-4931-b0b2-3b897c580b6c"},"source":["from google.colab import drive\n","#drive.mount('/content/drive', force_remount=True)\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dwOOFoanDQQC","executionInfo":{"status":"ok","timestamp":1623337552103,"user_tz":-60,"elapsed":236,"user":{"displayName":"Jack Stelling","photoUrl":"","userId":"10755116166180930038"}},"outputId":"ea5e20b2-8316-43d3-cb93-2d02b333ac00"},"source":["import os \n","\n","os.getcwd()\n","\n","os.listdir('/content/drive/MyDrive/Deeplabv3Flat')\n","os.listdir('/content/drive/MyDrive/Datasets')\n","\n","os.chdir('/content/drive/MyDrive/Deeplabv3Flat')\n","print('Directory Changed')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Directory Changed\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rN2nQRrRPHAY","executionInfo":{"status":"ok","timestamp":1623338311426,"user_tz":-60,"elapsed":696166,"user":{"displayName":"Jack Stelling","photoUrl":"","userId":"10755116166180930038"}},"outputId":"c8077653-36f8-488d-bb93-5d50a1259a33"},"source":["# camera-ready\n","\n","import sys\n","\n","! pip install import-ipynb\n","import import_ipynb\n","\n","#sys.path.append(\"/content/drive/MyDrive/Deeplabv3Flat\")\n","from datasets import DatasetVal # (this needs to be imported before torch, because cv2 needs to be imported before torch for some reason)\n","\n","# Dont need becuase of the flat file structure\n","#sys.path.append(\"/content/drive/MyDrive/Deeplabv3Flat\")\n","from deeplabv3 import DeepLabV3\n","\n","#sys.path.append(\"/root/deeplabv3/utils\")\n","from utils import label_img_to_color\n","\n","import torch\n","import torch.utils.data\n","import torch.nn as nn\n","from torch.autograd import Variable\n","import torch.optim as optim\n","import torch.nn.functional as F\n","\n","import numpy as np\n","import pickle\n","import matplotlib\n","matplotlib.use(\"Agg\")\n","import matplotlib.pyplot as plt\n","import cv2\n","\n","trainId_to_id = {\n","    0: 7,\n","    1: 8,\n","    2: 11,\n","    3: 12,\n","    4: 13,\n","    5: 17,\n","    6: 19,\n","    7: 20,\n","    8: 21,\n","    9: 22,\n","    10: 23,\n","    11: 24,\n","    12: 25,\n","    13: 26,\n","    14: 27,\n","    15: 28,\n","    16: 31,\n","    17: 32,\n","    18: 33,\n","    19: 0\n","}\n","trainId_to_id_map_func = np.vectorize(trainId_to_id.get)\n","\n","batch_size = 2\n","\n","best_trained_model = 'model_2_epoch_85.pth' # NB put the file name of best weight checkpoint \n","\n","network = DeepLabV3(\"eval_val_for_metrics\", project_dir=\"/content/drive/MyDrive/Deeplabv3Flat\").cuda()\n","network.load_state_dict(torch.load(\"/content/drive/MyDrive/Deeplabv3Flat/training_logs/model_2/checkpoints/\" + best_trained_model))\n","\n","val_dataset = DatasetVal(cityscapes_data_path=\"/content/drive/MyDrive/Datasets/Cityscapes\",\n","                         cityscapes_meta_path=\"/content/drive/MyDrive/Datasets/Cityscapes/meta\")\n","\n","num_val_batches = int(len(val_dataset)/batch_size)\n","print (\"num_val_batches:\", num_val_batches)\n","\n","val_loader = torch.utils.data.DataLoader(dataset=val_dataset,\n","                                         batch_size=batch_size, shuffle=False,\n","                                         num_workers=1)\n","\n","with open(\"/content/drive/MyDrive/Datasets/Cityscapes/meta/class_weights.pkl\", \"rb\") as file: # (needed for python3)\n","    class_weights = np.array(pickle.load(file))\n","class_weights = torch.from_numpy(class_weights)\n","class_weights = Variable(class_weights.type(torch.FloatTensor)).cuda()\n","\n","# loss function\n","loss_fn = nn.CrossEntropyLoss(weight=class_weights)\n","\n","network.eval() # (set in evaluation mode, this affects BatchNorm and dropout)\n","batch_losses = []\n","for step, (imgs, label_imgs, img_ids) in enumerate(val_loader):\n","    with torch.no_grad(): # (corresponds to setting volatile=True in all variables, this is done during inference to reduce memory consumption)\n","        imgs = Variable(imgs).cuda() # (shape: (batch_size, 3, img_h, img_w))\n","        label_imgs = Variable(label_imgs.type(torch.LongTensor)).cuda() # (shape: (batch_size, img_h, img_w))\n","\n","        outputs = network(imgs) # (shape: (batch_size, num_classes, img_h, img_w))\n","\n","        # compute the loss:\n","        loss = loss_fn(outputs, label_imgs)\n","        loss_value = loss.data.cpu().numpy()\n","        batch_losses.append(loss_value)\n","\n","        ########################################################################\n","        # save data for visualization:\n","        ########################################################################\n","        outputs = F.upsample(outputs, size=(1024, 2048), mode=\"bilinear\") # (shape: (batch_size, num_classes, 1024, 2048))\n","\n","        outputs = outputs.data.cpu().numpy() # (shape: (batch_size, num_classes, 1024, 2048))\n","        pred_label_imgs = np.argmax(outputs, axis=1) # (shape: (batch_size, 1024, 2048))\n","        pred_label_imgs = pred_label_imgs.astype(np.uint8)\n","\n","        for i in range(pred_label_imgs.shape[0]):\n","            pred_label_img = pred_label_imgs[i] # (shape: (1024, 2048))\n","            img_id = img_ids[i]\n","\n","            # convert pred_label_img from trainId to id pixel values:\n","            pred_label_img = trainId_to_id_map_func(pred_label_img) # (shape: (1024, 2048))\n","            pred_label_img = pred_label_img.astype(np.uint8)\n","\n","            cv2.imwrite(network.model_dir + \"/\" + img_id + \"_pred_label_img.png\", pred_label_img)\n","\n","val_loss = np.mean(batch_losses)\n","print (\"val loss: %g\" % val_loss)\n"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Collecting import-ipynb\n","  Downloading https://files.pythonhosted.org/packages/63/35/495e0021bfdcc924c7cdec4e9fbb87c88dd03b9b9b22419444dc370c8a45/import-ipynb-0.1.3.tar.gz\n","Building wheels for collected packages: import-ipynb\n","  Building wheel for import-ipynb (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for import-ipynb: filename=import_ipynb-0.1.3-cp37-none-any.whl size=2976 sha256=20b5c4e6359604c5c0ea76ca74d4996a85cbed7269029b9f99e71435ea40c202\n","  Stored in directory: /root/.cache/pip/wheels/b4/7b/e9/a3a6e496115dffdb4e3085d0ae39ffe8a814eacc44bbf494b5\n","Successfully built import-ipynb\n","Installing collected packages: import-ipynb\n","Successfully installed import-ipynb-0.1.3\n","importing Jupyter notebook from datasets.ipynb\n","importing Jupyter notebook from deeplabv3.ipynb\n","importing Jupyter notebook from resnet.ipynb\n","importing Jupyter notebook from aspp.ipynb\n","importing Jupyter notebook from utils.ipynb\n","pretrained resnet, 18\n","num_val_batches: 250\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3328: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n","  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n","/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3458: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n","  \"See the documentation of nn.Upsample for details.\".format(mode)\n"],"name":"stderr"},{"output_type":"stream","text":["val loss: 0.538642\n"],"name":"stdout"}]}]}