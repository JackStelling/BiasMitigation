{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"setup.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyP7yL93v1I0N7QNYEuBvzAN"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"-MQeig5qfmrt"},"source":["from typing import NamedTuple\n","from types import SimpleNamespace\n","import torch\n","import datetime\n","import os\n","import argparse\n","from logger import logger\n","from typing import Optional\n","from dataclasses import dataclass, field\n","\n","# Default device\n","DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","# DEVICE = 'cpu'\n","\n","# Parse arguments\n","parser = argparse.ArgumentParser()\n","parser.add_argument('--batch_size', type=int,\n","                    help='size of batch')\n","parser.add_argument('--epochs', type=int,\n","                    help='max number of epochs')\n","parser.add_argument('--z_dim', type=int,\n","                    help='dimensionality of latent space')\n","parser.add_argument('--alpha', type=float,\n","                    help='importance of debiasing')\n","parser.add_argument('--num_bins', type=int,\n","                    help='importance of debiasing')\n","parser.add_argument('--max_images', type=int,\n","                    help='total size of database')\n","parser.add_argument('--eval_freq', type=int,\n","                    help='total size of database')\n","parser.add_argument('--debias_type', type=str,\n","                    help='type of debiasing used')\n","parser.add_argument(\"--path_to_model\", type=str,\n","                        help='Path to stored model')\n","parser.add_argument(\"--num_workers\", type=int,\n","                        help='Path to stored model')\n","parser.add_argument(\"--debug_mode\", type=bool,\n","                        help='Debug mode')\n","parser.add_argument(\"--use_h5\", type=bool,\n","                        help='Use h5')\n","parser.add_argument(\"--folder_name\", type=str,\n","                        help='folder_name_to_save in')\n","parser.add_argument(\"--eval_name\", type=str,\n","                        help='eval name')\n","parser.add_argument('--stride', type=float,\n","                    help='importance of debiasing')\n","parser.add_argument('--eval_dataset', type=str,\n","                    help='Name of eval dataset [ppb/h5_imagenet/h5]')\n","parser.add_argument('--save_sub_images', type=bool,\n","                    help='Save images')\n","parser.add_argument('--model_name', type=str,\n","                    help='name of the model to evaluate')\n","parser.add_argument('--hist_size', type=bool,\n","                    help='Number of histogram')\n","parser.add_argument('--run_mode', type=str,\n","                    help='Type of main.py run')\n","parser.add_argument('-f', type=str,\n","                    help='Path to kernel json')\n","\n","\n","class EmptyObject():\n","    def __getattribute__(self, idx):\n","        return None\n","\n","ARGS, unknown = parser.parse_known_args()\n","if len(unknown) > 0:\n","    logger.warning(f'There are some unknown args: {unknown}')\n","\n","num_workers = 5 if ARGS.num_workers is None else ARGS.num_workers\n","\n","def create_folder_name(foldername):\n","    if foldername == \"\":\n","        return foldername\n","\n","    suffix = ''\n","    count = 0\n","    while True:\n","        if not os.path.isdir(f\"results/{foldername}{suffix}\"):\n","            foldername = f'{foldername}{suffix}'\n","            return foldername\n","        else:\n","            count += 1\n","            suffix = f'_{count}'\n","\n","def create_run_folder(folder_name):\n","    if len(folder_name) > 0:\n","        return create_folder_name(folder_name)\n","\n","    return create_folder_name(str(datetime.datetime.now().strftime(\"%d_%m_%Y---%H_%M_%S\")))\n","\n","@dataclass\n","class Config:\n","    # Running main for train, eval or both\n","    run_mode: str = 'both' if ARGS.run_mode is None else ARGS.run_mode\n","    # Folder name of the run\n","    run_folder: str = '' if ARGS.folder_name is None else ARGS.folder_name\n","    # Path to CelebA images\n","    path_to_celeba_images: str = 'data/celeba/images'\n","    # Path to CelebA bounding-boxes\n","    path_to_celeba_bbox_file: str = 'data/celeba/list_bbox_celeba.txt'\n","    # Path to ImageNet images\n","    path_to_imagenet_images: str = 'data/imagenet'\n","    # Path to evaluation images (Faces)\n","    path_to_eval_face_images: str = 'data/ppb/PPB-2017/imgs'\n","    # Path to evaluation metadata\n","    path_to_eval_metadata: str = 'data/ppb/PPB-2017/PPB-2017-metadata.csv'\n","    # Path to evaluation images (Nonfaces such as Imagenet)\n","    path_to_eval_nonface_images: str = 'data/imagenet'\n","    # Path to stored model\n","    path_to_model: Optional[str] = ARGS.path_to_model\n","    # Path to h5\n","    path_to_h5_train: str = 'data/h5_train/train_face.h5'\n","    # Type of debiasing used\n","    debias_type: str = ARGS.debias_type or 'none'\n","    # name of the model to evaluate\n","    model_name: str = ARGS.model_name or 'model.pt'\n","    # Random seed for reproducability\n","    random_seed: int = 0\n","    # Device to use\n","    device: torch.device = DEVICE\n","    # eval file name\n","    eval_name: str = ARGS.eval_name or \"evaluation_results.txt\"\n","    # Batch size\n","    batch_size: int = ARGS.batch_size or 256\n","    # Number of bins\n","    num_bins: int = ARGS.num_bins or 10\n","    # Epochs\n","    epochs: int = ARGS.epochs or 50\n","    # Z dimension\n","    z_dim: int = ARGS.z_dim or 200\n","    # Alpha value\n","    alpha: float = ARGS.alpha or 0.01\n","    # stride used for evaluation windows\n","    stride: float = ARGS.stride or 0.2\n","    # Dataset size\n","    max_images: int = ARGS.max_images or -1\n","    # Eval frequence\n","    eval_freq: int = ARGS.eval_freq or 5\n","    # Number workers\n","    num_workers: int = 5 if ARGS.num_workers is None else ARGS.num_workers\n","    # Image size\n","    image_size: int = 64\n","    # Number windows evaluation\n","    sub_images_nr_windows: int = 15\n","    # Evaluation window minimum\n","    eval_min_size: int = 30\n","    # Evaluation window maximum\n","    eval_max_size: int = 64\n","    # Uses h5 instead of the imagenet files\n","    use_h5: bool = True if ARGS.use_h5 is None else ARGS.use_h5\n","    # Debug mode prints several statistics\n","    debug_mode: bool = False if ARGS.debug_mode is None else ARGS.debug_mode\n","    # Dataset for evaluation\n","    eval_dataset: str = ARGS.eval_dataset or 'ppb'\n","    # Images to save\n","    save_sub_images: bool = False if ARGS.save_sub_images is None else ARGS.save_sub_images\n","    # Hist size\n","    hist_size: int = 1000 if ARGS.hist_size is None else ARGS.hist_size\n","    # Batch size for how many sub images to batch\n","    sub_images_batch_size: int = 10\n","    # Minimum size for sub images\n","    sub_images_min_size: int = 30\n","    # Maximum size for sub images\n","    sub_images_max_size: int = 64\n","    # Stride of sub images\n","    sub_images_stride: float = 0.2\n","\n","    def __post_init__(self, printing=False):\n","        self.run_folder = create_run_folder(self.run_folder)\n","        if printing:\n","            logger.save(f\"Saving new run files to {self.run_folder}\")\n","\n","\n","def init_trainining_results(config: Config):\n","    # Write run-folder name\n","    if not os.path.exists(\"results\"):\n","        os.makedirs(\"results\")\n","\n","    config.__post_init__(printing=True)\n","    os.makedirs(\"results/\"+ config.run_folder + '/best_and_worst')\n","    os.makedirs(\"results/\"+ config.run_folder + '/bias_probs')\n","    os.makedirs(\"results/\"+ config.run_folder + '/reconstructions')\n","\n","    with open(f\"results/{config.run_folder}/flags.txt\", \"w\") as write_file:\n","      write_file.write(f\"z_dim = {config.z_dim}\\n\")\n","      write_file.write(f\"alpha = {config.alpha}\\n\")\n","      write_file.write(f\"epochs = {config.epochs}\\n\")\n","      write_file.write(f\"batch size = {config.batch_size}\\n\")\n","      write_file.write(f\"eval frequency = {config.eval_freq}\\n\")\n","      write_file.write(f\"max images = {config.max_images}\\n\")\n","      write_file.write(f\"debiasing type = {config.debias_type}\\n\")\n","\n","\n","    if config.debug_mode:\n","        os.makedirs(f\"results/{config.run_folder}/debug\")\n","\n","    with open(f\"results/{config.run_folder}/training_results.csv\", \"a+\") as write_file:\n","        write_file.write(\"epoch,train_loss,valid_loss,train_acc,valid_acc\\n\")\n","\n","    with open(f\"results/{config.run_folder}/flags.txt\", \"w\") as wf:\n","        wf.write(f\"debias_type: {config.debias_type}\\n\")\n","        wf.write(f\"alpha: {config.alpha}\\n\")\n","        wf.write(f\"z_dim: {config.z_dim}\\n\")\n","        wf.write(f\"batch_size: {config.batch_size}\\n\")\n","        wf.write(f\"max_images: {config.max_images}\\n\")\n","        wf.write(f\"use_h5: {config.use_h5}\\n\")\n","\n","default_config = Config()"],"execution_count":null,"outputs":[]}]}